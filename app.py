import gradio as gr
import os
import openai
import anthropic
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
APP_PASSWORD = os.getenv("APP_PASSWORD")

# Inicializar clientes
openai_client = openai.OpenAI()
anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# Funci√≥n principal de traducci√≥n
def translate_and_transform(text, transformation, openai_model, anthropic_model, llama_model):
    prompt = f"""
Traduce el siguiente texto al ingl√©s nivel C1, aplicando esta transformaci√≥n gramatical: {transformation}.

Texto: {text}

Formato de salida:
B2: ...
C1: ...
Diferencias: ...
"""
    try:
        openai_response = openai_client.chat.completions.create(
            model=openai_model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        ).choices[0].message.content.strip()
    except Exception as e:
        openai_response = f"‚ùå OpenAI error: {str(e)}"

    try:
        anthropic_response = anthropic_client.messages.create(
            model=anthropic_model,
            max_tokens=1000,
            temperature=0.7,
            system="Eres un traductor experto en ingl√©s C1.",
            messages=[{"role": "user", "content": prompt}]
        ).content[0].text.strip()
    except Exception as e:
        anthropic_response = f"‚ùå Anthropic error: {str(e)}"

    # Aqu√≠ deber√≠as integrar LLaMA si tienes acceso o usar Hugging Face Inference API
    llama_response = f"(Simulaci√≥n) Traducci√≥n con modelo {llama_model}:\n\nB2: [traducci√≥n simulada]\n\nC1: [versi√≥n avanzada simulada]\n\nDiferencias: explicaci√≥n simulada"

    return openai_response, anthropic_response, llama_response

# Funci√≥n de acceso con contrase√±a
def verify_password(password):
    if password == APP_PASSWORD:
        return gr.update(visible=False), gr.update(visible=True), ""
    else:
        return gr.update(visible=True), gr.update(visible=False), "‚ùå Contrase√±a incorrecta"

# Interfaz Gradio
with gr.Blocks(theme=gr.themes.Monochrome()) as demo:
    gr.Markdown("# üîê Traductor C1 - Acceso restringido")

    with gr.Column(visible=True) as login:
        pwd = gr.Textbox(label="Introduce la contrase√±a", type="password")
        login_btn = gr.Button("Entrar")
        login_msg = gr.Markdown("")

    with gr.Column(visible=False) as app:
        gr.Markdown("## üß† Traductor avanzado de espa√±ol a ingl√©s - Nivel C1")

        input_text = gr.Textbox(label="Texto en espa√±ol", lines=3)

        transformation = gr.Radio(
            choices=[
                "3¬™ Condicional Invertida",
                "Inversi√≥n Enf√°tica",
                "Cleft Sentence",
                "Relative Clause"
            ],
            label="Transformaci√≥n gramatical",
            elem_classes="uniform-buttons"
        )

        with gr.Row():
            openai_model = gr.Dropdown(
                choices=["gpt-4o", "gpt-4", "gpt-3.5-turbo"],
                label="Modelo OpenAI",
                value="gpt-4o"
            )
            anthropic_model = gr.Dropdown(
                choices=["claude-3-opus-20240229", "claude-3-sonnet-20240229"],
                label="Modelo Anthropic",
                value="claude-3-opus-20240229"
            )
            llama_model = gr.Dropdown(
                choices=["meta-llama/Meta-Llama-3-8B-Instruct", "meta-llama/Meta-Llama-2-13B-chat"],
                label="Modelo LLaMA",
                value="meta-llama/Meta-Llama-3-8B-Instruct"
            )

        translate_button = gr.Button("üîÅ Traducir")

        with gr.Row():
            openai_output = gr.Textbox(label="üß† OpenAI", lines=10)
            anthropic_output = gr.Textbox(label="ü§ñ Anthropic", lines=10)
            llama_output = gr.Textbox(label="ü¶ô LLaMA (simulado)", lines=10)

    login_btn.click(verify_password, inputs=[pwd], outputs=[login, app, login_msg])
    translate_button.click(
        translate_and_transform,
        inputs=[input_text, transformation, openai_model, anthropic_model, llama_model],
        outputs=[openai_output, anthropic_output, llama_output]
    )

demo.launch()
